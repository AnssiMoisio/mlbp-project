{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Basic Principles 2018 - Data Analysis Project Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Comparing neural networks and logistic regression in music classification* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project compares logistic regression and neural networks in music classification. The data is composed of 264-dimensional feature vectors which each represent one song classified in one of ten music genres. The dataset has qualities, such as class imbalance, high dimensionality and the small size of the training dataset, that pose difficulties for the classifying. The data is first analysed with principal components analysis and by other methods. After that, the data is classified first using a logistic regression model created with the SciKit-learn library and then with a deep neural network created with the Keras library. The unlabelled test data is also experimented on by clustering the data, but the results were poor by this method. The neural network yielded slightly better results than the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a classifier nowadays is easier than ever, though building a good classifier is still a hard task despite the high availability of efficient tools created for this purpose. We wanted to investigate the performance of a minimally-tuned neural network in classification using out-of-the-box libraries and compare them to logistic regression. We chose Keras because of its popularity and documentation availability and SciKit-learn for the logistic regression implementation.\n",
    "\n",
    "The data usually has many problems some of which cannot be known beforehand. Preprocessing and visualisation are necessary for building a proper model. However, data analysis is already quite ubiquitous and the need for better tools is ever-growing. Some people, who would benefit from machine learning and data analysis, might not even be aware of the current progress of the field nor the tools at all. If these people were made aware of the field it will overall benefit the society we live in. To this day, it still requires a data scientist/engineer to build the models because of the various bottlenecks present in data science. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supplied data contains 4363 labeled samples and 6544 unlabeled sample vectors. Every sample is a vector of length 264 which is composed of preprocessed properties of the original time-series data. There are 10 labels and the class distribution is unbalanced; almost half of the labeled samples have the same label which could lead to problems in classification. For example, we don't want the classifier to learn the class distribution of the training set because the class distribution might be completely different for the evaluation set. Some of the fields in the data contain almost identical values for the whole dataset which means these features cannot be used to differentiate samples. Some of the features may also be redundant and contribute nothing while having high variance amongst the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv', header=None).values\n",
    "labels = pd.read_csv('data/train_labels.csv', header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the label distribution of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot label distribution in training data\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.hist(labels, range=(0.5,10.5), bins=10, ec='black')\n",
    "plt.xlabel('label')\n",
    "plt.ylabel('quantity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the class imbalance can be seen clearly. It is also good to find out if the data is ordered to know if it needs to suffled before dividing it to training data and validation data. Here is a simple plot of the distribution of the labels in the csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(2, figsize=(15, 5))\n",
    "plt.plot(labels, marker='.', linestyle = 'None')\n",
    "plt.xlabel('index in csv file')\n",
    "plt.ylabel('label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Pop-rock songs are first in the file and the rest of the genres are distributed randomly after that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal components analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can understand the dimensionality better by principal components analysis. Here is a class that is created on basis of the last Python exercise of this course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, data, d):\n",
    "        self.data = data # raw data\n",
    "        self.d = d # number of dimensions in the compressed data\n",
    "        self.W_pca, self.eigvalues = self.compute_pca()\n",
    "\n",
    "    def compute_pca(self):\n",
    "        # Output: a d by D matrix W_pca, and all eigenvalues of Q\n",
    "\n",
    "        N = self.data.shape[0]\n",
    "        # step1: compute the sample cov. matrix Q\n",
    "        Q = np.matmul(np.transpose(self.data), self.data ) / N\n",
    "        #step2: compute the eigenvalues and eigenvectors\n",
    "        w, v = np.linalg.eig(Q)\n",
    "        #step3: Sort the eigenvectors by decreasing eigenvalues, choose the d largest eigenvalues, form W_pca\n",
    "        ind = np.argsort(w)[::-1]\n",
    "        W_pca = np.empty((self.d, self.data.shape[1]))\n",
    "        eigvalues = w\n",
    "        for i in range(self.d):\n",
    "            W_pca[i] = v[:,ind[i]]\n",
    "        \n",
    "        return W_pca.real, eigvalues # discard imaginary part\n",
    "\n",
    "    def plot_error(self,  max_d):\n",
    "        x=range(1,max_d+1)\n",
    "        errors=[sum(self.eigvalues[d:]) for d in x]\n",
    "        plt.plot(x, errors)\n",
    "        plt.xlabel('Number of principal components $d$')\n",
    "        plt.ylabel('Reconstruction error $\\mathcal{E}$')\n",
    "        plt.title('Number of principal components vs the reconstruction error')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_scatter(self):\n",
    "        # get x for d=2\n",
    "        X_2d = np.matmul(self.W_pca[:2,:],self.data[:,:,None])[:,:,0]\n",
    "        plt.figure(1, figsize=(10, 10))   \n",
    "        plt.scatter(X_2d[:2178,0], X_2d[:2178,1], 3, marker='o', color='blue')\n",
    "        plt.scatter(X_2d[2178:,0], X_2d[2178:,1], 3, marker='x', color='red')\n",
    "        plt.xlabel('First principal component')\n",
    "        plt.ylabel('Second principal component')\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def low_dim_data(self):\n",
    "        new_data = np.ndarray((self.data.shape[0], self.d))\n",
    "        for i in range(self.data.shape[0]):\n",
    "            new_data[i] = np.matmul(self.W_pca, self.data[i])\n",
    "        return new_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see roughly the ratio between the first, i.e. largest, principal components, the first five eigenvalues are printed and the reconstruction error is plotted for the first 30 principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(train_data, 50)\n",
    "print('The first 5 principal component eigenvalues:\\n', pca.eigvalues[:5].real)\n",
    "# plot the number of principal components vs the reconstruction error\n",
    "pca.plot_error(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first component is about four orders of magnitude larger than the second. A scatterplot can be created where the first two components are used as axes. To try to understand how the labels are distributed in this space, we colour the Pop-rock genre as blue and the rest red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.plot_scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not show clear division or clustering of the labels in this 2D space. The data can be scaled with a scikit-learn method and the PCA can be done again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaled_data = preprocessing.scale(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_scaled = PCA(scaled_data, 50)\n",
    "print(pca_scaled.eigvalues[:5].real)\n",
    "# plot the number of principal components vs the reconstruction error\n",
    "pca_scaled.plot_error(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scaled.plot_scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this scatterplot can be seen a slight shift in the direction of the 1st and 2nd principal components if we compare the Pop-rock class to the other classes. While the distrinction is quite clear there are still many datapoints which reside in both sides of the scatterplot indicating some similarities between different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a preprocessor class that does the scaling and other handling of the data, such as dividing it. We tried also balancing the data by generating new rows of the underrepresented classes. These new rows were copied instaces of the existing rows with some noise added to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class Preprocessor:\n",
    "\n",
    "    def __init__(self, path='data/', balance=True, mutation_rate=5e-2, scale=True):\n",
    "        self.balance \t\t = balance\n",
    "        self.scale \t\t\t = scale\n",
    "        self.mutation_rate \t = mutation_rate\n",
    "        self.data_path \t\t = path\n",
    "        self.raw_data_labels = pd.read_csv(self.data_path + 'train_labels.csv', header=None)\n",
    "        self.unique_labels\t = np.unique(self.raw_data_labels)\n",
    "        self.raw_data \t\t = self.load_raw_data('train_data.csv')\n",
    "        self.test_data\t\t = self.load_raw_data('test_data.csv')\n",
    "\n",
    "    def load_raw_data(self, file):\n",
    "        data = pd.read_csv(self.data_path + file, header=None).values\n",
    "        if self.scale:\n",
    "            data = preprocessing.scale(data)\n",
    "        return data\n",
    "\n",
    "    def balance_raw_data(self, data, labels, save_bal_data, bal_data_path):\n",
    "        distribution = {}\n",
    "        raw = np.hstack((labels, data))\n",
    "        for label in self.unique_labels:\n",
    "            distribution[int(label)] = 0\n",
    "        for label in labels:\n",
    "            distribution[int(label)] += 1\n",
    "        distmax = distribution[max(distribution, key=distribution.get)]\n",
    "        amount = 0\n",
    "        for key in distribution:\n",
    "            amount += distmax - distribution[key]\n",
    "        count = 0\n",
    "        tmp = np.empty((0, 265))\n",
    "        for label in self.unique_labels:\n",
    "            auxiliary_rows = raw[raw[:, 0] == label]\n",
    "            for _ in range(distmax - distribution[label]):\n",
    "                to_add = auxiliary_rows[np.random.randint(auxiliary_rows.shape[0])]\n",
    "                for elem in range(to_add.shape[0] - 1):\n",
    "                    rnd = np.random.uniform(1 - self.mutation_rate, 1 + self.mutation_rate)\n",
    "                    to_add[elem + 1] *= rnd\n",
    "                count += 1\n",
    "                if count % 1000 == 0:\n",
    "                    print(\"Processed count: \", count, \"/\", amount)\n",
    "                tmp = np.append(tmp, [to_add], axis=0)\n",
    "        raw = np.vstack((raw, tmp))\n",
    "        # optionally saves the data\n",
    "        # boolean save_bal_data and save path is given to class method 'divided_data()'\n",
    "        if save_bal_data:\n",
    "            pd.DataFrame(raw).to_csv(bal_data_path)\n",
    "        new_labels = raw[:, :1]\n",
    "        new_features = raw[:, 1:]\n",
    "        return new_features, new_labels\n",
    "\n",
    "    def label_filter(self, row, label: int):\n",
    "        #print(int(row[0])\n",
    "        return row[0] == label\n",
    "\n",
    "    # loads all feature vectors from training data and validation data for unsupervised learning\n",
    "    # shape: (num_of_vectors, 264)\n",
    "    def all_feature_vectors(self):\n",
    "        pass\n",
    "\n",
    "    # transforms the label data to vectors, for example: 2 => (0, 1, 0, 0, 0, 0, 0, 0, 0, 0)\n",
    "    # shape: \n",
    "    def transformed_labels(self, data):\n",
    "        unique_labels = np.unique(self.raw_data_labels)\n",
    "        labels = np.zeros((data.shape[0], unique_labels.shape[0]))\n",
    "        for i in range(data.shape[0]):\n",
    "            labels[i][int(data[i]) - 1] = 1\n",
    "        assert labels.shape == (data.shape[0], unique_labels.shape[0])\n",
    "        return labels\n",
    "\n",
    "    # normalises columns to [0.0, 1.0]\n",
    "    def normalize_data(self, data):\n",
    "        transformed = data\n",
    "        print(type(data))\n",
    "        return transformed\n",
    "\n",
    "    # divides training data according to ratio for training purposes: (training_data, training_labels), (testing_data, testing_labels)\n",
    "    # shape: (ratio*4263, col), ((1 - ratio)*4363, col)\n",
    "    # loads preprocessed data from file or preprocesses the data and optionally saves to file\n",
    "    def divided_data(self, ratio=0.5, bal_data_path=None, load_bal_data=True, save_bal_data=False):\n",
    "        # path to balanced data file is used for both loading and saving the file\n",
    "        if not bal_data_path:\n",
    "            # appends ratio in percentages to file name\n",
    "            bal_data_path = self.data_path + 'bal_data_ratio_' + str(int(100*ratio)) + '.csv'\n",
    "\n",
    "        raw = np.hstack((self.raw_data_labels, self.raw_data))\n",
    "        np.random.shuffle(raw)\n",
    "        num = int(ratio * raw.shape[0])\n",
    "        training_data = raw[:num, 1:]\n",
    "        training_labels = raw[:num, :1]\n",
    "\n",
    "        # balance the data\n",
    "        if (self.balance and not load_bal_data):\n",
    "            training_data, training_labels = self.balance_raw_data(training_data, training_labels, save_bal_data, bal_data_path)\n",
    "\n",
    "        # use old balanced data file\n",
    "        if (self.balance and load_bal_data):\n",
    "            raw = pd.read_csv(bal_data_path, header=None).values\n",
    "            # pandas puts headers as first column and row\n",
    "            training_labels = raw[1:, 1:2]\n",
    "            training_data = raw[1:, 2:]\n",
    "\n",
    "        testing_data = raw[num:, 1:]\n",
    "        testing_labels = raw[num:, :1]\n",
    "        return training_data, training_labels, testing_data, testing_labels\n",
    "\n",
    "    # returns columns (1-168)\n",
    "    # shape: (row, 168)\n",
    "    def get_rhythm_patterns(self, data):\n",
    "        return data[:,0:168]\n",
    "\n",
    "    # return columns (169-216)\n",
    "    # shape: (row, 48)\n",
    "    def get_chroma(self, data):\n",
    "        return data[:,168:216]\n",
    "\n",
    "    # return columns 217-264\n",
    "    # shape: (row, 48)\n",
    "    def get_mfcc(self, data):\n",
    "        return data[:,216:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we tried balancing the data with this class, we noticed that balancing did not improve the results. For this reason, we do not use balanced data in the rest of this notebook. The next cell loads the data from the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessor object and load the data\n",
    "dl = Preprocessor(balance=False, scale=True)\n",
    "x_train, y_train, x_test, y_test = dl.divided_data(ratio=0.8, load_bal_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods and experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried a few different methods including logistic regression, neural networks and clustering. The first two gave sufficient results while clustering gave a very poor accuracy. The poor performance of the clustering algorithms might be due to many reasons, such as imbalance and high dimensionality of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SciKit-learn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we tried the logistic regression classifier from the SciKit library. We tried some different solvers and noticed the 'Stochastic Average Gradient'[3] solver to work best. Below, the logistic regression is fitted. This should take about half a minute with max_iter=500. More iterations do not seem to improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# The classifier\n",
    "clf = LogisticRegression(random_state=0, solver='saga',multi_class='multinomial', max_iter=500, verbose=1)\n",
    "\n",
    "# Fit the data\n",
    "model = clf.fit(x_train, y_train)\n",
    "\n",
    "# Predict labels\n",
    "prediction = model.predict(x_test)\n",
    "\n",
    "# Plot the accuracy\n",
    "print(\"train score: \", clf.score(x_train, y_train))\n",
    "print(\"test score: \", clf.score(x_test, y_test))\n",
    "\n",
    "# print logloss\n",
    "clf_probs = clf.predict_proba(x_test)\n",
    "score = log_loss(y_test, clf_probs)\n",
    "print(\"test log-loss: \", score)\n",
    "\n",
    "# plot label distribution of the prediction\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.hist(prediction, range=(0.5,10.5), bins=10, ec='black')\n",
    "plt.xlabel('label')\n",
    "plt.ylabel('quantity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives an accuracy of about 65% on the test data and the label distribution looks about the same as the true distribution. We see that we can achieve a decent result with little work using the SciKit library. We tried also clustering with SciKit. The acc help method is from [4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "\n",
    "nmi = normalized_mutual_info_score\n",
    "ari = adjusted_rand_score\n",
    "\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "    ind = linear_assignment(w.max() - w)\n",
    "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "x, y, notused, notused2 = dl.divided_data(ratio=1, load_bal_data=False)\n",
    "y = y.reshape((len(y),))\n",
    "\n",
    "# 10 clusters\n",
    "n_clusters = 10\n",
    "\n",
    "# Reduce dimensions with PCA:\n",
    "#pca = PCA(x, 10)\n",
    "#x = pca.low_dim_data()\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    y_pred = kmeans.fit_predict(x)\n",
    "\n",
    "print(\"accuracy with kmeans: \", acc(y, y_pred))\n",
    "\n",
    "# plot label distribution of the prediction\n",
    "plt.figure(1, figsize=(8, 8))\n",
    "plt.hist(y_pred, range=(-0.5,9.5), bins=10, ec='black')\n",
    "plt.xlabel('label')\n",
    "plt.ylabel('quantity')\n",
    "plt.title('Clustering prediction label distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not get any good results from our experiments with clustering. We tried changing various details, such as balancing the data (see the Preprocessing class) and using features with reduced dimensions by PCA. The best accuracy was 50% but this was achieved just by classing all songs in the Pop-rock class that is 50% of the training data. Therefore 50% is not a good result considering how it was attained. We discarded the method of clustering in our final model which we created with Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep network with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to test how a modern neural network library performs. We first separated the data into thee distrinct categories according to the data description: rhythm, chroma and MFCC. We then put each of these in separate inputs and made a shallow network to interpret the data. Afterward we combined the results into a single layer which was followed by a deep layer composition. The hyperparameters were chosen mainly by testing out different ones and looking for the best ones. Last layer uses softmax activation explicitly since we wanted to use the same results for both competitions. Log-loss values were the direct values from the last layer and labels where chosen by the largest element in the 10-long label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Input layers need the labels as vectors of ten, e.g. 2 = (0, 1, 0, 0, 0, 0, 0, 0, 0, 0)\n",
    "y_train_net = dl.transformed_labels(y_train)\n",
    "y_test_net = dl.transformed_labels(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cells require installing Keras. Training of the model might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, concatenate, Dense, Dropout, BatchNormalization, GRU, GaussianNoise\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "rhythm_input = Input(shape=(168,)) # timesteps, timestep dimension\n",
    "chroma_input = Input(shape=(48,)) # timesteps, timestep dimension\n",
    "mfcc_input \t = Input(shape=(48,)) # timesteps, timestep dimension\n",
    "\n",
    "rhythm  = Dense(168, activation='tanh', kernel_regularizer=l1_l2(1e-6, 1e-6))(rhythm_input)\n",
    "rhythm  = Dropout(rate=0.3)(rhythm)\n",
    "rhythm  = Dense(42, activation='softmax', kernel_regularizer=l1_l2(1e-6, 2e-6))(rhythm)\n",
    "rhythm  = Dropout(rate=0.4)(rhythm)\n",
    "\n",
    "chroma  = Dense(48, activation='tanh', kernel_regularizer=l1_l2(1e-6, 1e-6))(chroma_input)\n",
    "chroma  = Dropout(rate=0.3)(chroma)\n",
    "chroma  = Dense(48, activation='tanh', kernel_regularizer=l1_l2(1e-6, 1e-6))(chroma)\n",
    "chroma  = Dropout(rate=0.4)(chroma)\n",
    "\n",
    "mfcc    = Dense(48, activation='tanh', kernel_regularizer=l1_l2(1e-6, 1e-6))(mfcc_input)\n",
    "mfcc    = Dropout(rate=0.3)(mfcc)\n",
    "mfcc    = Dense(48, activation='tanh', kernel_regularizer=l1_l2(1e-6, 1e-6))(mfcc)\n",
    "mfcc    = Dropout(rate=0.4)(mfcc)\n",
    "\n",
    "classifier \t = concatenate([rhythm, chroma, mfcc], axis=-1)\n",
    "\n",
    "for rate in range(3):\n",
    "    classifier = Dense(120, activation='tanh', kernel_regularizer=l1_l2(1e-6, 1e-6))(classifier)\n",
    "    classifier = Dropout(rate=0.3)(classifier)\n",
    "\n",
    "classifier = Dense(10, activation='softmax', kernel_regularizer=l1_l2(1e-7, 1e-6))(classifier)\n",
    "\n",
    "input_data = [\n",
    "    x_train[:, :168],\n",
    "    x_train[:, 168:216],\n",
    "    x_train[:, 216:]\n",
    "]\n",
    "\n",
    "validation_data = [\n",
    "    x_test[:, :168],\n",
    "    x_test[:, 168:216],\n",
    "    x_test[:, 216:]\n",
    "]\n",
    "\n",
    "tensorboardCB = keras.callbacks.TensorBoard(log_dir='./Graph', \n",
    "                                          histogram_freq=1,  \n",
    "                                          write_graph=True, \n",
    "                                          write_images=True)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "sgd = SGD(momentum=0.1, nesterov=True)\n",
    "\n",
    "model = Model(inputs=[rhythm_input, chroma_input, mfcc_input], outputs=classifier)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(input_data, y_train_net, \n",
    "                validation_data=(validation_data, y_test_net), \n",
    "                batch_size=256, \n",
    "                epochs=300)\n",
    "\n",
    "# predict\n",
    "prediction_net = model.predict(validation_data)\n",
    "# convert probabilities into labels\n",
    "y_classes = prediction_net.argmax(axis=-1) \n",
    "# shift classes from 0-9 to 1-10\n",
    "y_classes = np.subtract(y_classes, [-1]*len(y_classes)) \n",
    "# plot the label distribution\n",
    "plt.figure(2, figsize=(10, 8))\n",
    "plt.title(\"prediction label distribution\")\n",
    "plt.hist(y_classes, range=(0.5,10.5), bins=10, ec='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix we can see which labels are confused as each other. The confusion matrix code is from [5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_m = confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(__doc__)\n",
    "\n",
    "import itertools\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_confusion_matrix(cm, classes=['1','2','3','4','5','6','7','8','9','10'],\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(conf_m,\n",
    "                      title='Confusion matrix for SciKit-learn logistic regression, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(conf_m, normalize=True,\n",
    "                      title='Normalized confusion matrix for SciKit-learn logistic regression')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix produced by the regression based classifier indicates that the regression has trouble separating class 1 from other classes. Class 1 was by large the most abundant sample class available which explains why the simple regression classifies too many samples to class 1.\n",
    "\n",
    "The same problem can be seen with the network model. The neural network based implementation has a similar confusion matrix and it also has some problem separating the rest of the classes from class 1. The classes that were most underrepresented were difficult for both of the models, mostly the classes 7 and 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix for the Keras deep network model\n",
    "conf_m = confusion_matrix(y_test, y_classes)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(conf_m,\n",
    "                      title='Confusion matrix, without normalization for Keras deep network')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(conf_m, normalize=True,\n",
    "                      title='Normalized confusion matrix for Keras deep network')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log loss for the logistic regression model was about 1.2 and for the neural network about 1.4 when calculated on the validation data. However, the result in Kaggle was about 0.2, which we assume is because of a slightly different definition of the log loss calculation. The neural network implementation faired a little better in misclassifying wrong samples as class 1. However, we believe better results could be obtained by hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion/Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network yielded similar results to the logistic regression with slightly higher performance. Since we wanted to use the same network for both competitions we were not able to tailor the model for the individual competitions which may affect the overall performance of the model. First problem we ran into when designing the network were that the network learned the class distribution of the training dataset instead of generalizing based on the features. Unbalanced data remains a non-trivial problem to be solved.\n",
    "\n",
    "It might be feasible to build a pipeline for the classification: since the classes are quite inbalanced (for example, class 1 being almost half of the samples) we could build a classifier that tells us whether a sample belongs to class 1 or not. Latter result makes the model advance in its pipeline to a classifier that classifies a somewhat evenly distributed dataset next (for example, classes 4-8 in the next classifier). Then it could advance to a stage where it checks whether a sample belongs to class 2 or to set of classes (3, 9, 10). Latter result would then differentiate between class 3 and set (9, 10) and then at the last stage it would identify whether the sample belongs to class 9 or class 10.\n",
    "\n",
    "Class inbalance could also be handled with creating dummy data. We tried duplicating the low-count samples and sometimes even mutating them to make them distinct from the original data but this kind of preprocessing did not give us better results. A generative adversarial network may yield sufficient results for this purpose but we did not have the time to test GANs [2].\n",
    "\n",
    "The neural net performed quite well (64% accuracy) as did the logistic regression (62% accuracy). The difference was a little larger when we returned the results to Kaggle, i.e. when the models were tested with completely new data. This suggests that the neural net was able to generalize better and not overfit to the training data as much as the logistic regression model did. We were unable to achieve results over 70% with the validation data (checking was done during the training). We tried different optimizers and went with Adam since it can be expected to converge faster than other optimizers [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [1] https://arxiv.org/abs/1412.6980v8\n",
    " \n",
    " [2] https://arxiv.org/abs/1406.2661\n",
    " \n",
    " [3] https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions\n",
    " \n",
    " [4] https://github.com/Tony607/Keras_Deep_Clustering\n",
    " \n",
    " [5] http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
